# Cletho RAG MVP Project ‚Äì Session Summary  
**Date:** 2025-08-25 & 2025-08-26  
**Facilitator:** ChatGPT  
**Participants:** Rick (Clear Thought Labs)

---

## 1. Next Steps

- Finalize and document the memory architecture for the Cletho RAG system.
- Design and scaffold the RAG corpus structure, including metadata tagging strategy.
- Begin draft architecture for the MVP RAG system using Supabase as the data backend.
- Establish a session journaling workflow using daily `.md` files.
- Configure persistent memory upload + retrieval pipeline using local Markdown session files.
- Define first-pass decision matrix step scripts and identify where RAG retrieval will occur.
- Explore classifiers for distinguishing user replies, user questions, and statements.
- Decide on embedding strategy for semantic search over session context.
- Discuss chunking vs summarization for RAG input construction.
- Clarify design tradeoffs between embedding raw session turns and distilled summaries.

---

## 2. Current Decisions

- **Session file format:** Each session summary will follow the 5-section Markdown structure.
- **Transcript inclusion:** Full session transcripts will be embedded directly in the `.md` file.
- **Working definition of ‚Äúsession‚Äù:** A single temporally bounded interaction, usually daily.
- **Memory boundary types:** Three are in play ‚Äî Decision Cycle, Decision Step, Session.
- **RAG search methods:** Cletho‚Äôs MVP will support keyword, semantic, and metadata filtering.
- **Backend database:** Supabase selected, with emphasis on clear boundary between user vs system data.
- **Session journaling method:** Rick will upload the prior day‚Äôs `.md` file at session start.
- **Session file management:** ChatGPT will integrate past context by processing the most recent file and threading from there.

---

## 3. Key Previous Decisions

- **Division of system components:**  
  1. Known/standard (e.g. frontend/backend infra).  
  2. Documented/unfamiliar (e.g. RAG stack).  
  3. Novel/custom (e.g. Cletho‚Äôs decision-partnering behavior).  

- **Cletho's RAG usage:** RAG will be invoked both in response to user questions and as part of scripted Cletho prompts.

- **Embedding session context:** Leaning toward using a distilled summary rather than raw turn history for context embedding, but undecided.

- **Source corpus:** Cletho will retrieve only from curated, internal knowledge bases ‚Äî no live external APIs.

---

## 4. Key RAG Design Considerations and Constraints

- Cletho, not the user, is the active agent in most query flows ‚Äî requiring RAG queries to be generated internally.
- A classifier is likely needed to distinguish among user statements, clarifying questions, and RAG-triggering queries.
- Session summarization is likely needed for memory persistence and efficient semantic search.
- The retrieval corpus will include multiple types of knowledge (domain, procedural, examples) and must be tagged accordingly.
- Clear separation between user-generated data (e.g. session transcripts, decision content) and system data (e.g. BK, TK, EK) is required.

---

## 5. Full Transcript of Session

### Combined transcript from 2025-08-25 and 2025-08-26:

# Project Plan: Minimum Viable RAG System (7 Weeks)

## Context

**Rick:**

I need you to help me make a project plan to build a minimum viable RAG system in the next seven weeks. Let me lay out the assumptions and whatnot, and we'll take this one step at a time.

Looking at the entire system and how it's going to work ‚Äî which is still somewhat vague right now ‚Äî Jeff and I have divided it into three categories:

1. **Things we know how to do and have done before**  
   Examples: standard front end and back end development.

2. **Things we have not done before, but which are well documented**  
   Examples: RAG system development, where there is plenty of documentation and even open-source code to tweak and use.

3. **Things that are brand new, with no real frame of reference**  
   Example: a *Cletho* construct that asks questions and deftly draws information out of a user to support rational decision-making.

That last category is definitely the hardest. Jeff and I will spend a month working side-by-side on it, starting in about seven weeks. That effort will focus on the **construction and interpretation of the decision matrix**, which we expect to be a 6‚Äì7 step process. The plan is to build a *minimum viable first set of steps*, then incrementally build them out in a spiral fashion. The goal at this stage is simply **proof of concept**.

To do that, we need a **minimum viable RAG system**. Having just finished the Coursera RAG course, I can see how RAG normally works to augment user prompts. In the case of Cletho ‚Äî where it‚Äôs Cletho asking the questions (or prompting) and processing the answers to construct the next prompt, not the user ‚Äî it‚Äôs not yet clear how it‚Äôs going to work.

---

**Chat:**

Excellent framing ‚Äî thank you.  
That three-part breakdown (1: familiar engineering, 2: documented but new territory, 3: novel design challenges) is a strong scaffold for this seven-week push. Let me reflect back the core intent, then sketch a structure for the project plan.



## üîç Clarifying Your Project Goal

Your immediate aim is to build a **Minimum Viable RAG (MVRAG) system** that can support Cletho‚Äôs decision-making dialogue engine. The RAG system should be:

- **Functional enough** to demonstrate how retrieval can support a multi-turn, system-initiated dialogue,  
- **Minimal enough** that it doesn‚Äôt overcommit to implementation details not yet finalized for the ‚ÄúCletho Core,‚Äù  
- **Robust enough** that when you and Jeff start your deep design sprint (~7 weeks), you‚Äôre not held back by infrastructure, data prep, or brittle code.  

Correct?



## üõ†Ô∏è Nature of the Challenge

You‚Äôre building a **system-prompted RAG pipeline**, not a user-prompted one.

| Standard RAG             | Cletho‚Äôs Variant                         |
|---------------------------|------------------------------------------|
| User asks a question      | Cletho asks a question                   |
| System retrieves docs     | System retrieves docs                    |
| System generates response | User provides the response               |
| System continues dialogue | Cletho generates the next question       |

This raises **open questions**:

- How will the RAG system know what to retrieve if the user isn‚Äôt driving the query?  
- Should it retrieve based on Cletho‚Äôs current question, or based on the user‚Äôs last response?  
- Or should the entire session so far be used as a context window for retrieval?  

Your MVP RAG will need to **pick one of these assumptions and stick with it (for now).**



## üìÜ Seven-Week Spiral Project Plan

I suggest a **4-phase spiral**, mapped to weeks:

| Phase            | Timeframe  | Goal                                                                 |
|------------------|------------|----------------------------------------------------------------------|
| 1. Baseline      | Week 1     | Simple user-prompted RAG with local corpus                           |
| 2. Cletho Mode 1 | Weeks 2‚Äì3  | RAG pulls docs based on Cletho‚Äôs question                            |
| 3. Cletho Mode 2 | Weeks 4‚Äì5  | RAG pulls docs based on user responses                               |
| 4. Integration   | Weeks 6‚Äì7  | Hardened module for use in decision-matrix proof of concept          |

**Key Constraint:** The system should be **modular**, so that swapping ‚Äúuser question‚Äù with ‚ÄúCletho question‚Äù (in Week 2) is trivial.



## üéØ Week 1 Planning

By the end of **Week 1**, you should have:

- A **local corpus** (e.g., Markdown or JSON docs)  
- A working **retriever** (FAISS or Weaviate-lite)  
- An **LLM wrapper** (OpenAI for now)  
- A **CLI or notebook demo** showing:  
  `question ‚Üí retrieval ‚Üí response`



## üîß What I Need from You Now

To define the **Week 1 milestone and checklist**, I need to know:

1. **What stack/tools** do you want to use for MVP RAG?  
   - FAISS? Weaviate? LangChain? LlamaIndex? Just OpenAI + numpy?

2. **What documents** will be used in the MVP corpus?  
   - Markdown? Web scrapes? Cletho‚Äôs internal docs?

3. **Where will this run?**  
   - Jupyter? Local script? Streamlit prototype?

4. **What retrieval granularity?**  
   - Full doc? Paragraph? Sentence?



üëâ Once you decide on those, I‚Äôll sketch the **Week 1 milestone and deliverables**, with a checklist you can start implementing immediately.  

Let‚Äôs get precise.

---   
